version: '3'
services:
  nginx:
    build: .
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - chatui
    networks:
      - gateway_network
  mongodb:
    image: mongo:latest
    container_name: mongodb
    volumes:
      - ./mongo:/data/db
    ports:
      - "27017:27017"
    networks:
      - gateway_network
  chatui:
    build: 
      context: ./chat-ui
      dockerfile: Dockerfile
    container_name: chatui
    ports:
      - "3000:3000"
    depends_on:
      - mongodb
      - text-generation-inference
    networks:
      - gateway_network
  text-generation-inference:
    image: ghcr.io/huggingface/text-generation-inference:latest
    command: ["--max-total-tokens", "2600", "--max-input-length", "2048", "--max-batch-prefill-tokens", "2560", "--quantize", "awq", "--model-id", "TheBloke/deepseek-coder-33B-instruct-AWQ"]
    volumes:
      - $PWD/models:/data
    container_name: text-generation-inference
    deploy:
      resources:
        reservations:
          devices:
          - driver: "nvidia"
            device_ids: ["0"]
            capabilities: [gpu]
          memory: 1g
    networks:
      - gateway_network
networks:
  gateway_network:
    driver: bridge
